{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90860,"databundleVersionId":10740331,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import models\nfrom timm import create_model\nfrom PIL import Image","metadata":{"id":"vdMi4cTEsHSM","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:46:27.117199Z","iopub.execute_input":"2025-01-12T18:46:27.117464Z","iopub.status.idle":"2025-01-12T18:46:27.122299Z","shell.execute_reply.started":"2025-01-12T18:46:27.117442Z","shell.execute_reply":"2025-01-12T18:46:27.121234Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Change with path to your dataset path, you may check the exact path using the files tab (folder icon in the sidebar)\ntrain_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train\"\ntest_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test\"\n\n# Data Preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),  # Randomly flip the image vertically\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.RandomRotation(45),  # Increased rotation angle\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformations\n    transforms.ToTensor(),\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nOGtrain_dataset = ImageFolder(root=train_dir, transform=transform)\n# Assuming 'dataset' is your original dataset\nval_size = int(0.2 * len(OGtrain_dataset))  # 20% for validation\ntrain_size = len(OGtrain_dataset) - val_size\ntrain_dataset, val_dataset = random_split(OGtrain_dataset, [train_size, val_size])\n\n# Validate Class to Index Mapping\nprint(\"Class to Index Mapping:\", OGtrain_dataset.class_to_idx)\nprint(OGtrain_dataset.classes)","metadata":{"id":"p7zNtbM90MyD","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:46:27.123413Z","iopub.execute_input":"2025-01-12T18:46:27.123685Z","iopub.status.idle":"2025-01-12T18:46:27.235297Z","shell.execute_reply.started":"2025-01-12T18:46:27.123663Z","shell.execute_reply":"2025-01-12T18:46:27.234481Z"}},"outputs":[{"name":"stdout","text":"Class to Index Mapping: {'antelope': 0, 'bat': 1, 'beaver': 2, 'blue+whale': 3, 'bobcat': 4, 'buffalo': 5, 'chihuahua': 6, 'cow': 7, 'dalmatian': 8, 'deer': 9, 'dolphin': 10, 'elephant': 11, 'german+shepherd': 12, 'giant+panda': 13, 'giraffe': 14, 'grizzly+bear': 15, 'hamster': 16, 'hippopotamus': 17, 'humpback+whale': 18, 'killer+whale': 19, 'leopard': 20, 'lion': 21, 'mole': 22, 'mouse': 23, 'otter': 24, 'ox': 25, 'persian+cat': 26, 'pig': 27, 'polar+bear': 28, 'raccoon': 29, 'rat': 30, 'seal': 31, 'siamese+cat': 32, 'skunk': 33, 'spider+monkey': 34, 'tiger': 35, 'walrus': 36, 'weasel': 37, 'wolf': 38, 'zebra': 39}\n['antelope', 'bat', 'beaver', 'blue+whale', 'bobcat', 'buffalo', 'chihuahua', 'cow', 'dalmatian', 'deer', 'dolphin', 'elephant', 'german+shepherd', 'giant+panda', 'giraffe', 'grizzly+bear', 'hamster', 'hippopotamus', 'humpback+whale', 'killer+whale', 'leopard', 'lion', 'mole', 'mouse', 'otter', 'ox', 'persian+cat', 'pig', 'polar+bear', 'raccoon', 'rat', 'seal', 'siamese+cat', 'skunk', 'spider+monkey', 'tiger', 'walrus', 'weasel', 'wolf', 'zebra']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\n\nbatch_size = 4 # Adjust as needed\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:46:27.236988Z","iopub.execute_input":"2025-01-12T18:46:27.237230Z","iopub.status.idle":"2025-01-12T18:46:27.241276Z","shell.execute_reply.started":"2025-01-12T18:46:27.237212Z","shell.execute_reply":"2025-01-12T18:46:27.240469Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Training Setup\ninput_size = 224 * 224 * 3  # Flattened size of input images\nclass ConvNeXtWithDropout(nn.Module):\n    def __init__(self, dropout_rate=0.35, num_classes=2):\n        super(ConvNeXtWithDropout, self).__init__()\n        \n        # Load the pre-trained ConvNeXt model\n        self.convnext = timm.create_model('convnext_large', pretrained=True)\n        \n        # Remove the original classifier (head)\n        self.convnext.reset_classifier(0)\n        \n        # Add custom classifier with dropout\n        self.fc = nn.Sequential(\n            nn.Dropout(p=dropout_rate),  # Add dropout layer\n            nn.Linear(self.convnext.num_features, 512),  # Adjust input to match output features from ConvNeXt\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Linear(512, num_classes)  # Output layer\n        )\n        \n    def forward(self, x):\n        # Get features from ConvNeXt\n        x = self.convnext(x)\n        \n        # Pass through custom fully connected layers\n        return self.fc(x)\n        \nnum_classes = len(OGtrain_dataset.classes)\n# Example usage:\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ConvNeXtWithDropout(dropout_rate=0.35, num_classes=num_classes)  # 2 classes, you can change it to your required number of classes\n\n# Move the model to the selected device (GPU if available, else CPU)\nmodel = model.to(device)\n\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)\nfor param in model.parameters():\n    param.requires_grad = True\n\n","metadata":{"id":"jQd1JQ4_0Ssu","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:46:27.242791Z","iopub.execute_input":"2025-01-12T18:46:27.243107Z","iopub.status.idle":"2025-01-12T18:46:30.998643Z","shell.execute_reply.started":"2025-01-12T18:46:27.243078Z","shell.execute_reply":"2025-01-12T18:46:30.997916Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Example: Stop if validation accuracy doesn't improve for 3 consecutive epochs\nbest_val_accuracy = 0\npatience = 30\nepochs_without_improvement = 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:46:30.999461Z","iopub.execute_input":"2025-01-12T18:46:30.999757Z","iopub.status.idle":"2025-01-12T18:46:31.003869Z","shell.execute_reply.started":"2025-01-12T18:46:30.999727Z","shell.execute_reply":"2025-01-12T18:46:31.002950Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\n# Cosine Annealing Scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\nprint(\"This cell has begin execution\")\n# Training Loop\nnum_epochs = 50\nmodel.train()\nfor epoch in range(num_epochs):\n\n    running_loss = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n    \n    train_loss = running_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}\")\n\n# Validation phase\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Calculate accuracy\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    # Compute average validation loss and accuracy\n    val_loss /= len(val_loader)\n    val_accuracy = 100 * correct / total\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy= val_accuracy\n        epochs_without_improvement = 0\n    else:\n        epochs_without_improvement+=1\n\n    if epochs_without_improvement>=patience:\n        print(\"Early stopping\")\n        break\n    \n    # Step the scheduler \n    scheduler.step(val_loss)","metadata":{"id":"lDZk3mPe0VNg","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:46:31.004835Z","iopub.execute_input":"2025-01-12T18:46:31.005145Z","execution_failed":"2025-01-13T00:36:00.844Z"}},"outputs":[{"name":"stdout","text":"This cell has begin execution\nEpoch [1/50], Training Loss: 2.6482\nValidation Loss: 1.2858, Validation Accuracy: 87.63%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/50], Training Loss: 0.9543\nValidation Loss: 0.9511, Validation Accuracy: 90.04%\nEpoch [3/50], Training Loss: 0.8615\nValidation Loss: 0.9121, Validation Accuracy: 91.30%\nEpoch [4/50], Training Loss: 0.8241\nValidation Loss: 0.8977, Validation Accuracy: 91.56%\nEpoch [5/50], Training Loss: 0.8069\nValidation Loss: 0.8768, Validation Accuracy: 92.40%\nEpoch [6/50], Training Loss: 0.7823\nValidation Loss: 0.8810, Validation Accuracy: 92.30%\nEpoch [7/50], Training Loss: 0.7639\nValidation Loss: 0.8659, Validation Accuracy: 92.77%\nEpoch [8/50], Training Loss: 0.7482\nValidation Loss: 0.8734, Validation Accuracy: 92.92%\nEpoch [9/50], Training Loss: 0.7477\nValidation Loss: 0.8856, Validation Accuracy: 92.51%\nEpoch [10/50], Training Loss: 0.7377\nValidation Loss: 0.8922, Validation Accuracy: 92.09%\nEpoch [11/50], Training Loss: 0.7307\nValidation Loss: 0.8897, Validation Accuracy: 92.51%\nEpoch [12/50], Training Loss: 0.7264\nValidation Loss: 0.8652, Validation Accuracy: 93.13%\nEpoch [13/50], Training Loss: 0.7169\nValidation Loss: 0.8800, Validation Accuracy: 92.82%\nEpoch [14/50], Training Loss: 0.7163\nValidation Loss: 0.8777, Validation Accuracy: 92.66%\nEpoch [15/50], Training Loss: 0.7165\nValidation Loss: 0.8717, Validation Accuracy: 93.13%\nEpoch [16/50], Training Loss: 0.7126\nValidation Loss: 0.8841, Validation Accuracy: 93.03%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Prediction\nmodel.eval()\ntest_images = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]\ntest_predictions = []\n\nfor img_name in test_images:\n    img_path = os.path.join(test_dir, img_name)\n    image = Image.open(img_path).convert('RGB')\n    image = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        outputs = model(image)\n        predicted_class = torch.argmax(outputs, dim=1).item()\n        test_predictions.append((img_name, OGtrain_dataset.classes[predicted_class]))\n\n# Save Predictions\nsubmission = pd.DataFrame(test_predictions, columns=['image_id', 'class'])\nsubmission.to_csv(\"/kaggle/working/kaggle_resnet50.csv\", index=False)","metadata":{"id":"pLSg4S3F0Wl2","trusted":true,"execution":{"execution_failed":"2025-01-13T00:36:00.844Z"}},"outputs":[],"execution_count":null}]}